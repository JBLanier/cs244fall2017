{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS244 Assignment 5 - Group 8\n",
    "===============\n",
    "\n",
    "* Kevin Rothi (leader)\n",
    "* J.Y. Ku\n",
    "* John Lanier \n",
    "\n",
    "Github Repository \n",
    "https://github.com/JBLanier/cs244fall2017/ \n",
    "\n",
    "Overview\n",
    "----------------\n",
    "\n",
    "Our team used Python for this project. The venerable data science library SciKit Learn was the engine of our machine learning. We first parsed the data out of the xlsx file with the xlrd library, partitioned it, broke it up into windowed chunks, and then performed some basic feature engineering which resulted in linearly seperable data. A Support Vector Machine (SVM) was used as our classifier. We compare and contrast the performance of the extracted features against the raw data, and then test the trained learner on data we recorded from our sensor.\n",
    "\n",
    "\n",
    "### Parsing Data\n",
    "Since the data was delivered in a xlsx file, we had to use a third party library (xlrd) to extract the data from the spreadsheet. The resulting data was was in a list of lists, and we needed to convert the data into a numpy array.\n",
    "\n",
    "### Windowing\n",
    "This step was very similar to the kind of windowing we performed for assignment 3. The data was partitioned such that each chunk corresponded to a specific time window in the whole dataset. Note that we tried varying window sizes, from 6 to 12 seconds, and the impact of this was negligible on our final result due to the low noise in the data.\n",
    "\n",
    "### Feature Engineering\n",
    "We computed the standard deviation of the signal magnitude vector (SMV) as a feature to perform machine learning on. We reasoned that the variation in motion as represented by the feature would be an excellent indicator of activity. It turns out that using this feature results in a linearly separable dataset, and the support vector machine had a perfect classification rate using this feature alone. The standard deviation of the motion data has a robust statistical correlation to the activity being performed, at least for this dataset.\n",
    "\n",
    "### Machine Learning\n",
    "As per instruction, we used a Support Vector Machine (SVM) to build a statistical model between the feature vector and the target vector. The SVM builds a decision boundary which maximally separates the data, and this learner fits the data well (hopefully) without overfitting. It generalizes well since the data exhibits such statistical regularity when the appropraite features are generated.\n",
    "\n",
    "### Engineered Features vs Unconditioned Data\n",
    "For comparison, we trained on the raw XYZ data. As expected, it performed worse in cross validation since the raw data isn't as separable as the engineered feature. The learner trained on the XYZ data was able to successfully classify the data ~93.8% of the time, compared to the 100% of the time the learner trained on the standard deviation of the SMV performed at.\n",
    "\n",
    "### Testing Real Data\n",
    "As an exercise, we tested our learner on data we collected from our sensor. The data was generated from a walking person, but the label the SVM assigned to it was a \"1\" (sleeping). The training data provided for this assignment is at a different scale than the data provided by our sensor. While the provided data lists values of around \"6\" on some axis during sleeping, our sensor would never provide more than around \"1.1\" for the same activity. When classifying our own data, we will need to create our own training data from the same source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy using raw features only, X Y Z: 0.9378666666666667\n",
      "Cross Validation Accuracy using standard deviation of signal magnitude vector only: 1.0\n",
      "Classification for 5 seconds of walking using our own sensor's data (Shouldn't make sense due to different scales): 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import xlrd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from numpy import genfromtxt\n",
    "\n",
    "#------------- PULLING IN DATA -----------------\n",
    "workbook = xlrd.open_workbook('XYZ.xlsx') # data provided for hw\n",
    "worksheet = workbook.sheet_by_index(0) # need to use this janky library to open the xlsx file\n",
    "\n",
    "real = genfromtxt('RLdata.csv', delimiter=',') # real world data we collected\n",
    "real = real[1:,:]\n",
    "real = np.array(real).reshape(-1, 3)\n",
    "\n",
    "offset = 1 # avoid the column headers\n",
    "\n",
    "columns = [] # the matrix to build up\n",
    "for j, col in enumerate(range(worksheet.ncols)):\n",
    "    if (j == 0): #skip time column\n",
    "        continue\n",
    "    c = []\n",
    "    for i, row in enumerate(range(worksheet.nrows)):\n",
    "        if i < offset: #skip column headers\n",
    "            continue\n",
    "        c.append(worksheet.cell_value(i, j))\n",
    "    columns.append(c)\n",
    "\n",
    "#print (columns[0]) # EXAMPLE: X values for activity 1\n",
    "#------------------------------------------------\n",
    "\n",
    "#------------- DEFINING UTILITY FUNCTIONS -----------------\n",
    "def getActivity(activity): # pass in the activity you want to get a matrix for\n",
    "    return columns[(activity - 1) * 4: ((activity - 1) * 4) + 3]\n",
    "\n",
    "def getMaxWindow(data, size): # returns the highest window possible --- size is in seconds!\n",
    "    return math.floor(len(data) / (size * 50))\n",
    "\n",
    "def getWindow(activityMatrix, winNumber, size): # winNumber is count 0, size is in seconds!\n",
    "    window = [] # the new matrix to populate\n",
    "    for col in range(len(activityMatrix)):\n",
    "        window.append(activityMatrix[col][winNumber * size * 50: (winNumber * size * 50) + (size * 50)])\n",
    "    return window\n",
    "#----------------------------------------------------------\n",
    "\n",
    "#------------- FEATURE EXTRACTION FUNCTIONS -----------------\n",
    "def getSignalMagnitudeVector(windowedData): # returns an array of the same length with the SMV\n",
    "    SMV = []; # to populate\n",
    "    for row in range(len(windowedData[0])):\n",
    "        SMV.append(math.sqrt(math.pow(windowedData[0][row], 2) +  math.pow(windowedData[1][row], 2) + math.pow(windowedData[2][row], 2)))\n",
    "    return SMV\n",
    "\n",
    "def getStandardDeviation(smv): # calculates the std of the smv\n",
    "    return np.std(smv)\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Now we're going to get into the real substance of the assignment\n",
    "# The first thing we're going to do is to build of a matrix of\n",
    "# feature vectors and target (label) vectors...\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "clf = svm.SVC()\n",
    "X = []\n",
    "Y = []\n",
    "rawXYZData = []\n",
    "rawTargets = []\n",
    "realDataFeatures = []\n",
    "\n",
    "for activity in [1, 2, 3, 4, 5]:\n",
    "    for window in range(getMaxWindow(columns[0], 6)):\n",
    "        windowedActivityData = getWindow(getActivity(activity), window, 6)\n",
    "        for rawDataIndex in range(len(windowedActivityData[0])):\n",
    "            rawXYZData.append([windowedActivityData[0][rawDataIndex], windowedActivityData[1][rawDataIndex], windowedActivityData[2][rawDataIndex]])\n",
    "            rawTargets.append(activity)\n",
    "        X.append(getStandardDeviation(getSignalMagnitudeVector(windowedActivityData)))\n",
    "        Y.append(activity)\n",
    "        \n",
    "X = np.array(X).reshape((-1, 1))\n",
    "\n",
    "realDataFeatures = getStandardDeviation(getSignalMagnitudeVector(real))\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Now we train up a learner and get a 5-fold cross validation score\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "X, Y = shuffle(X, Y)\n",
    "rawXYZData, rawTargets = shuffle(rawXYZData, rawTargets)\n",
    "\n",
    "scores = cross_val_score(clf, rawXYZData, rawTargets)\n",
    "print('Cross Validation Accuracy using raw features only, X Y Z: {}'.format(np.mean(scores)))\n",
    "\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "print('Cross Validation Accuracy using standard deviation of signal magnitude vector only: {}'.format(np.mean(scores)))\n",
    "\n",
    "clf.fit(X, Y)\n",
    "print('Classification for 5 seconds of walking using our own sensor\\'s data (Shouldn\\'t make sense due to different scales): {}'.format(clf.predict(realDataFeatures)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
